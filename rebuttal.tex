\documentclass[11pt, oneside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry,color}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for rotated page geometry
%\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex		
\usepackage{amssymb}

%SetFonts

%SetFonts


%\title{Brief Article}
%\author{The Author}
%\date{}							% Activate to display a given date or no date

\begin{document}
%\maketitle

\noindent
The Editor\\
Quantitative Science Studies\\

We thank the reviewers for their constructive critiques, which we have attempted to respond to in a systematic manner below and in a revision of the manuscript.

\section{Reviewer 1}

\emph{This study focuses specifically on a potential flaw in a study by Uzzi, Mukherjee, Stringer, \& Jones  (2013).  Uzzi et al. used articles from the WoS database. They developed an indicator of conventionality and innovativeness for each article by focusing on the pairs of references within each article- and the corresponding pairs of journals associated with those pairs of references.  Journals were assumed to represent areas of knowledge.  Articles that built upon journal-pairs that were commonly mentioned together represented conventionality.  Articles that built upon journals pairs that were rarely mentioned together represented innovativeness. They found that articles with high conventionality and high innovative (HC; HI) were more highly cited (a commonly used indicator that the paper has had a greater impact).  Uzzi et al. also went through a variety of sensitivity analyses to show that the results held across different disciplinary fields (they used standard definitions of disciplines).}     

\emph{ This study doesn't question the database.  They don't question the assumption that conventionality and innovativeness can be detected by calculating within-article journal co-occurrences. Their point of departure is in the calculation of z-scores (the deviation of journal co-occurences from expected values). Uzzi et al. used a random reference substitution approach to determine z-scores. The authors in this article suggest that substitutions should not be random.  One doesn't substitute a reference to a physics journal with a reference to a social science journal.  Substitutions should be within the local field.  Using their alternative approach, they show that Uzzi et al's central finding (that high conventionality and high innovativeness results in higher impact across many disciplines) does not apply equally across the three broadly defined fields they focused on: applied physics, immunology and metabolism.   They found that It doesn't apply equally across WoS disciplinary categories. This is, in essence, a highly focused methodological critique of an article that was published over five years ago.  As such, the technical contribution of this article, while important, may be marginal. The authors seem to suggest that their new substation approach should be used. I'm not convinced.}

\textcolor{blue}{
George - I think that it's not  true that we don't question the assumption that
conventionality and innovativeness can be detected by calculating journal co-occurrences.
I realize it's not the most important thing to discuss, but perhaps we should not leave that
statement completely alone.}

The reviewer is correct. We do not question the database--the Web of Science is sufficiently comprehensive to conduct such studies. We are puzzled by the comment about the technical contribution being marginal. It is true that Uzzi was published five years ago but, with the exception of Boyack and Klavans (2014), it seems to have been uncritically cited over 175 times since. 

\emph{As such, I recommend that the authors resubmit the article after resolving the following issues.
1.  Focus on the issue at hand.  Much of the early text is totally off the point of the study.  This is not a study in semantics. Nor is it about co-citation analysis and disciplinary affects.   The title seems totally misleading.  The article is about a very narrow methodological issue: whether the construction of Z-scores using a random substitution model is inherently biased vis-à-vis construction of Z-scores using a local substitution model.  So if the authors choose to rewrite- please edit out all of the superfluous material. It's a huge distraction.} 

We have revised the text to reflect these suggestions. We have not changed the title. The methodological concern only has relevance in the larger context of co-citation analysis and differences between disciplinary citation practice. 

\emph{2.  Realize that the proposed approach is also flawed.  On the surface- it would make sense- don't substitute an anthropology journal for a physics journal. But deeper down, it may not make sense because there is no agreed upon way to decide what is `local' and what isn't.   Does one use word searches to define fields (as suggested by the authors)?   Subject categories?   And since there's so much latitude in what one could use- aren't you running the risk of getting a false negative because of misspecification of the discipline?  
Stated differently, the proposed approach may be equally flawed because most highly influential journals (such as Science and Nature) can't be assigned to fields or disciplines.   These highly influential journals were found to have an excessively strong effect on the indicator of conventionality and innovativeness in Uzzi's study (see Boyack \& Klavans, 2014)- so a change in how the Z-score is calculated for this group will have a disproportional effect on the results.   It's not clear how does this new approach address this issue.  Science and Nature (and the other high influence journals) can publish across all three of their fields (immunology, applied physics and metabolism)- who should their cohort group be?  If a very small set of journals can have such a huge influence on the outcome- will the local substitution approach really help or hurt?}

The reviewer makes very valid points. In citing Boyack and Klavans (2014), we also reiterate that there are journal effects that we do not investigate in this study. However, we would like to point out that a keyword search defines a set of articles without modifying the references cited in those publications. 
In our approach, the expected values for z-score calculations are calculated from those references cited by the authors of those articles instead of the indiscriminate substitutions of Uzzi. An argument for our approach is the K-L measurements showing less model misspecification in our approach compared to Uzzi's.

\textcolor{blue}{George, I think it would be good to say that we do not assert that our model/method is unflawed -- in fact we acknowledge this explicitly, and will make that point even stronger. But we do note that we establish a reduction in model misspecification in using our model compared to Uzzi et al.'s model, and so even if our model is flawed (and it will be), it is less flawed than Uzzi's. }

\emph{3. Provide more concrete evidence that one approach is better than the other.  For example- use Uzzi's approach and your new approach to nominate the `high innovative' and `high conventional' papers.   Then focus on differences in these sets- the papers that are HI-using the old method vs. HI using the new method; HC-old vs. HC-new method; LI new vs. LI old; LC new vs. LC old).  Rely on a third approach to make the judgment about which approach is better (such as the recent work by Henry Small that detects whether a paper is a discovery paper using citance analysis). I suspect that, if one is trying to identify innovative papers, citance analysis that focuses on discovery (as a surrogate for innovation) is a reasonable approach- and gives a more concrete way of assessing the merits of the two approaches. Since these sets of papers can (and should) be made public- others can also see (for themselves) which method really works best.} 

Again, we thank the reviewer. We have revised the text of our manuscript to make it more clear that we're not endorsing this approach. 
\textcolor{blue}{An important point in our paper (which we clearly didn't make strongly
enough)  is that we are not
proposing that our model (which restricts the substitutions to a defined citation network) be used to
define conventionality and innovativeness. Instead, our point is not to propose a new model, but rather to show that a small change in the model results in a reduction in model misspecification and presents very different trends. Hence, any conclusions based on Uzzi's model that are not
also seen when analyzing the WoS using our model are likely to be the result of 
model misspecification.
[Tandy please insert your points here..].}  We're not trying to identify innovative papers--our point is more that the proxy measure for impact suggests that HC flavored with HI (as defined by Uzzi) is not a universal feature of highly cited papers. A mixed methods approach where qualitative judgment is brought to bear on the quantitative results as per (Ioannidis, Klavans, and Boyack) is an excellent suggestion, but we think it's beyond the scope of this manuscript.
 
\section{Reviewer 2}

\emph{This paper builds on the Uzzi et al (2013) Science paper.  It argues that a local network approach (rather than Uzzi's global network approach) is appropriate for identifying unusual combinations.  It also shows that Uzzi's findings regarding the relationship between novelty X conventionality and citation impact does not hold when using the local network approach. I really enjoyed reading this paper and believe that it is an important contribution: the topic and findings are important, data analysis is thorough, and paper is well-written.}

Thank you. 
 
\emph{However, one major concern is about whether a local network is indeed more appropriate than a global network.  The authors did give very convincing arguments.  However, it can be argued that most atypical combinations are cross-disciplinary.  By using a local network for reference swapping, these cross-disciplinary atypical combinations will not be identified as such.  At the fundamental level, what is the relationship between novelty and interdisciplinary?  Clearly they are not empirically independent of each other, but what about their conceptual relationship?  Should we consider novelty as something net of interdisciplinary, such that a local network is appropriate in order to clear out interdisciplinarity, or should we consider novelty as something that is related with interdisciplinarity, such that a global network is needed for not missing cross-disciplinary unusual combinations.  I would suggest the authors do develop a clear conceptualization of novelty before claiming that local network is appropriate.  In addition, it might be interesting to separate within-discipline and cross-discipline novelty and examine their effects on citation impact.}

This is a very important point that is also brought up by Reviewer 1 so we would like to reiterate that our approach does not alter the original references cited by the authors of the articles we assemble into datasets. We u

\textcolor{blue}{George,  think it would good to re-iterate that we are not proposing a new model be used in subsequent studies. We are just showing a dramatic reduction in model misspecification by restricting to local networks, and that trends shown for our model (which by K-L divergences is superior to Uzzi's model) are very different from what were seen for Uzzi's model.  }

\emph{Figure 2 is informative, it shows that when using local network instead of global network, the Uzzi finding still holds for the whole WoS database but not for applied physics, immunology, or metabolism.  However, there are two possible explanations: (1) Uzzi's findings are not universal across fields, and (2) difference in using local vs. global networks.  It would be helpful to replicate the same plots using Uzzi's global network approach and single out which factor made the difference.}
 
\emph{On page 2, `In addition, under this random model, a reference cited many times in a given year is selected with the same probability as a reference cited only once, which appears inconsistent with the power law or lognormal citation distributions described in the literature.'  I do not quite understand this.  In Uzzi's reference swapping, for each references, its total number of forward citations is preserved, so at the system level, a reference with fewer citations does have a smaller probability of being swapped.  So I do not exactly understand this criticism.}

Our apologies for not being clear. In examining the shuffling code of Uzzi (kindly shared by Satyam Mukkherjee and Ben Jones), we realized that the choice of substitutions was restricted to the set rather than the multi-set of eligible references. The reciprocal substitution approach ensures that the total number of references is still preserved after shuffling but selection is equiprobable. The points below may serve to illustrate our point.

a) Consider a toy dataset slice of 5 publications all published in the same year. Each of these publications cites 4 references, thus, 20 citations. Of these, one (which we will call $x$) is cited in each of the publications (thus cited 5 times) and the remaining 15 are cited once in total. During citation shuffling (i)  in our approach, the probability of selecting $x$ would be 5/20. In Uzzi it would be 1/20. Further, Uzzi's code allows 20 successive substitution attempts if the original reference is selected. Thus, it favors creating diversity in the expected values. 

b) In a local or a global network it does not make sense to treat a highly cited reference as equiprobable with a reference cited only once. 

c) We should add a section on Jim's analysis showing 2.5\% of the references are affected- for a distribution in which the top 1-2\% qualify as highly cited then it becomes important.

\end{document}  