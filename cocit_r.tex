%% Documentclass:
%% Network Neuroscience
%\documentclass[finalfonts,NETN]{stjour}
\documentclass[NETN]{stjour}

%% or 

%% Manuscript, for double spaced, larger fonts
%\documentclass[manuscript]{stjour}
%% Only needed if you use `manuscript' option
% \journalname{Network Neuroscience}


%%%%%%%%%%% Article Set-Up %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Article Type:
%% Default is Research.

%% Or, choose one of these options:
%% Research, Methods, Data, Review, and Perspective

\articletype{Research Article}

%%%%%%%%%%% Please supply information %%%%%%%%%%%%%%%%%%%%%%%%%

\supportinginfo{dx.doi.org/10.7910/DVN/PQ6ILM}

%% if no conflicts, this command doesn't need to be used
%% \conflictsofinterest{}

%%%%%%%%%%% to be supplied by MIT Press, only %%%%%%%%%%%%%%%%%
\citation{Betzel, R. F., Fukushima, M.,
He, Ye,
Zuo, Xi-Nian,
Sporns, O. (2016)\\
Dynamic fluctuations coincide with periods of high and low modularity
in resting-state functional brain  networks\\
Network Neuroscience, 1
}

\received{20 October 2016}
\accepted{7 November 2016}
\published{26 January 2016}
\setdoi{10.1162/NETN-00001} %% ???

\handlingeditor{Xi-Nian Zuo}

%%%%%%%% End MIT Press commands %%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% author definitions should be placed here:

%% example definition
\def\taupav{\tau_{\mathrm{Pav}}}

\begin{document}
\title[Co-citations in context]{Co-citations in context}
\subtitle{disciplinary heterogeneity is relevant}

%% If shortened title for running head is needed so that the article title can fit
%%   in the running head, use [] argument, ie,
%%
%%   \title[Shortened Title for Running Head]{Title of Article}
%%   \subtitle{Subtitle Here}

%% Since we use \affil{} in the argument of the \author command, we
%% need to supply another version of the author names, without \affil{}
%% to be used for running heads:

\author[Author Names]
{James Bradley\affil{1},
Sitaram Devarakonda\affil{2}, Avon Davey\affil{2}, Dmitriy Korobskiy\affil{2}, Siyu Liu\affil{2}, Tandy Warnow\affil{3}
\and George Chacko\affil{2}}

\affiliation{1}{Raymond A. Mason School of Business, College of William and Mary, Williamsburg, VA, USA}
\affiliation{2}{Netelabs, NET ESolutions Corporation, McLean, VA 22102, USA}
\affiliation{3}{Department of Computer Science, University of Illinois at Urbana-Champaign, Champaign, IL 61820, USA}


%ie.
%\affiliation{1}{Gatsby Computational Neuroscience Unit, University
%College London, London, United Kingdom} 

%\affiliation{2}{Another Department, Institution, City, Country}

%ie
%\affiliation{2}{Center for Studies in
%Behavioral Neurobiology, Concordia University, Montreal, Quebec,
%Canada}

\correspondingauthor{George Chacko}{netelabs@nete.com}

% ie,
%\correspondingauthor{Ritwik K. Niyogi}{ritwik.niyogi@gatsby.ucl.ac.uk}

\keywords{(bibliometrics, co-citation analysis, random graphs )}

%ie
%\keywords{work, leisure, normative, microscopic,  reinforcement learning, economics}

\begin{abstract}
Citation analysis of the scientific literature has been used to study and define disciplinary boundaries, to trace the dissemination of knowledge, and to estimate impact. Co-citation, the frequency with which pairs of publications are cited, provides insight into how documents relate to each other and across fields. Co-citation analysis has been used to characterize combinations of prior work as conventional or innovative and to deriveå features of highly cited publications. Given the organization of science into disciplines, a key question is the sensitivity of such analyses to frame of reference. Our study examines this question using  semantically-themed citation networks. We observe that trends reported to be true across the scientific literature do not hold for focused citation networks, and conclude that co-citation analysis requires a contextual perspective.
\end{abstract}

% \begin{authorsummary} 
% \end{authorsummary}


\section{Introduction}
Citation and network analysis of  scientific literature reveals information on semantic relationships between publications, collaboration between scientists, and the practice of citation itself~\citep{garfield_citation_1955,de_solla_price_networks_1965,newman_structure_2001,Shi:2010:CHI:1816123.1816131,patience_pmid28560354}. Co-citation, the frequency with which two documents are cited together in other documents provides additional insights, including the identification of semantically related documents, fields, idea, and specialization in science~\citep{small_co-citation_1973,marshakova-shaikevich_co-citation_1973,boyack_co-citation_2010, 10.3389/frma.2018.00020}. 

\cite{uzzi_atypical_2013} used a novel approach for co-citation analysis of 17.9 million articles and their cited references from the Web of Science (WoS)  to characterize a subset of highly cited articles with respect to both novel and conventional combinations of prior research. Observed co-citation frequencies, mapped to journals, were computed across the dataset and normalized (shifted and scaled) to expected values generated by Monte Carlo simulations under a random graph model. These normalized journal pair frequencies were termed \emph{z-scores} (Materials and Methods). Thus, every article was associated with multiple z-scores. For each article, positional statistics of these z-scores were calculated to describe conventionality: high conventionality (HC) if the median z-score for an article was greater than the median of median z-scores of all articles and low conventionality for the inverse (LC). Similarly,  an article was deemed to have high novelty (HN) if the tenth percentile of its z-scores  was negative and low novelty (LN) for the inverse. Accordingly, each article was labeled with respect to conventionality and novelty, e.g, HCHN (denoting that the article exhibits both high conventionality and high novelty), with all four combinations being possible. 
\citep{uzzi_atypical_2013} observed that HCHN articles were twice as likely to be found in highly cited papers, suggesting that novel combinations of ideas flavoring a body of conventional thought were a recipe for impact across the scientific literature. 

Key to Uzzi {\em et al.}, however, is their random graph model and its underlying assumptions. A careful examination of the model (as defined by the Monte Carlo simulation) reveals that random substitutions of references used to generate expected values are equiprobable, which means that a reference in an article can be substituted by any other reference randomly chosen from those published in the same year, irrespective of disciplinary focus and citation count. For example, the model permits substitution of a reference in quantum physics with equal probability by a reference in classical literature, evolutionary biology, or anthropology. Such substitutions poorly model documented citation behavior~\citep{wallace_lariviere_gingras_2012,moed_measuring_2010,klavans_research_2017,garfield_1979}. In addition, under this random model,  a reference cited over 100 times in a given year is selected with the same probability as a reference cited only once, which is inconsistent with the frequency distribution of citations characterized as power law or lognormal~\citep{stringer_statistical_2010,perline_strong_2005}.  Lastly, while the citation switching algorithm used in Uzzi preserves the number of publications and the number of references in each publication, it does not preserve the disciplinary proportions of cited references within the network. Accordingly, the expected value calculations generated by the \citep{uzzi_atypical_2013} simulations and used in characterizing journal pairs in terms of conventionality and novelty  can be reasonably questioned on grounds of model mis-specification. 

A follow-up study by \citep{boyack_vs_uzzi_2014}  explored the impact of discipline and journal effects on the definition of conventionality and novelty.  While their study had some methodological differences from \citep{uzzi_atypical_2013} in the use of Scopus data and a $\chi^2$ calculation for expected values, Boyack and Klavans find the same basic trend that HCHN is more probably in highly cited papers. However, they note that ``only 64.4\%  of  243  WoS  subject  categories'' in the Uzzi {\em et al.} study met the criterion of having the highest probability of hit papers in the HCHN category.  Further, they observed that journals vary widely in terms of size and influence and that 20 journals accounted for nearly 15\% of co-citations in their measurements. Lastly, they noted that three multidisciplinary journals accounted for 9.4\% of all atypical combinations, suggesting strong effects from both disciplines and journals that were not reported by Uzzi et al. 

Despite different methods used to generate expected values, both \citep{uzzi_atypical_2013} and \citep{boyack_vs_uzzi_2014}  measured observed frequencies across the scientific literature without disciplinary constraints and subsequently used normalized frequencies to examine disciplinary subsets. In contrast, we chose to consider disciplinary organization in science by first constructing semantically related sets of documents (disciplinary networks) and then measuring observed and expected frequencies within these networks. 

Accordingly, we used keyword searches of the scientific literature to create three citation networks themed around broad search terms. Within these disciplinary frameworks, we calculated expected values using a random graph model that accounted for existing citation frequencies and an efficient Monte Carlo simulation algorithm that permitted a substantially greater number of simulations while preserving the number of publications, references, and disciplinary proportions in the network. We hypothesized that our approach would  reduce model misspecification and better simulate citation practice, in turn leading to different and more relevant conclusions. Our study on these semantically-themed citation networks reveals significantly different patterns of conventionality and novelty between  citation networks and disciplines that challenges the conclusion that HCHN articles have a greater probability of being represented in highly cited publications. Instead, we conclude that conventional thought as commonly defined in our study, 
in \citep{uzzi_atypical_2013}, and  \citep{boyack_vs_uzzi_2014}, is more likely to drive higher citations..
 \emph{these are just filler conclusions that must be carefully rewritten and added to- need Jim's conclusions to be stated here.}.

\section{Materials and Methods}
\emph{Bibliographic data} We have previously developed ERNIE, an open source knowledge platform into which we parse the Web of Science (WoS) Core Collection~\citep{Keserci371955}. WoS data stored in ERNIE spans the period 1900-2019 and consists of over 72 million publications. For this study, we generated an analytical dataset from years 1985 to 2005. The total number of publications in this dataset was just over 25 million publications (25,134,073).  For each of these years, we further restricted analysis to those of type Article. Since WoS data also contains incomplete references or references that point at other indexes,  we also considered only those references for which there were complete records (Table 1). For example, WoS data for year 2005 contained 1,753,174 publications, which after restricting to type Article and considering only those references described above resulted in 916,573 publications, 6,095,594 unique references (set of references), and 17,167,347 total references (multiset of references). Given consistent trends in the data, we analyzed the two boundary years (1985 and 2005) and the mid-point (1995) performing 1,000 simulations for each dataset. \\
\emph{Disciplinary datasets} We constructed three disciplinary datasets based on keyword searches. (i) immunology (ii) metabolism (iii) applied physics. For the first two, rooted in biomedical research, we searched Pubmed for the term `immunology' or `metabolism' in the years 1985, 1995, and 2005. Pubmed IDs (pmids) returned were matched to WoS IDs (wos\_ids) and used to retrieve relevant articles. For the applied physics dataset, we directly searched subject labels in WoS for `applied physics'. \\
\emph{Normalization of observed and expected values} Building upon prior work~\cite{uzzi_atypical_2013}, all ${n \choose 2}$ reference pairs were generated for each publication, where $n$ is the number of cited references in the publication. These reference pairs were then mapped to the journals they were published in using ISSN numbers, to create journal pairs. Where multiple ISSN numbers exist for a journal, the most frequently used one in the WoS was assigned to the journal. In addition, publications containing less than two references were discarded. Journal pair frequencies were summed up across the dataset to create observed frequencies $(F_{obs})$. Null models were created by randomly shuffling references while preserving the number of publications, the number of references in each publication, and the frequency with which these references were cited within the year of interest. In contrast to the preceding study~\citep{uzzi_atypical_2013}, we generated 1,000 rather than 10 null models for each dataset.  Expected values $(F_{exp})$ for journal pairs were generated by averaging the result of 1,000 simulations. z-scores were calculated for each journal-pair using the formula $(F_{obs} - F_{exp})/\sigma$ where $\sigma$
 is the standard deviation of the frequencies generated by simulation. As a result of these calculations, each publication becomes associated with a set of z-scores corresponding to the journal pairs derived from pairwise combinations of its cited references and positional statistics (quantiles) of z-scores were calculated for each publication. Publications were also labeled according to conventionality and novelty. (i) HC if the median z-score exceeded the median of median z-scores for all publications. LC if the median z-score was equal to or less than the median of median z-scores for all publications (ii) HN if the tenth percentile of z-scores for a publication was less than zero. LN if the tenth percentile of z-scores for a publication was greater than zero. 

% latex table generated in R 3.5.3 by xtable 1.8-4 package
% Fri May 17 14:28:31 2019
\begin{table}[ht]
\caption{Summary of WoS Analytical Dataset. UP: unique publications, UR: unique references, TR: total references. The number of publications, unique references, total references and the ratio of total references to unique references increases monotonically with each year indicating that both the number of documents and citation activity increase over time. Data for reference years is flanked by horizontal lines and shown in boldface. Only publications of type Article and references with complete WoS records are included in these counts.}
\label{tab:label}
\centering
\begin{tabular}{|rrrrr|}
  \hline
Year & UP & UR & TR & TR/UR \\ 
  \hline
\textbf{1985} & \textbf{418495} & \textbf{2281297} & \textbf{5615496} & \textbf{2.46} \\ 
\hline
1986 & 402309 & 2316451 & 5708796 & 2.46 \\ 
1987 & 412936 & 2427347 & 5998513 & 2.47 \\ 
1988 & 426001 & 2545647 & 6354917 & 2.50 \\ 
1989 & 443144 & 2673092 & 6749319 & 2.52 \\ 
1990 & 458768 & 2827517 & 7209413 & 2.55 \\ 
1991 & 477712 & 2977784 & 7729776 & 2.60 \\ 
1992 & 492181 & 3134109 & 8188940 & 2.61 \\ 
1993 & 504488 & 3278102 & 8676583 & 2.65 \\ 
1994 & 523660 & 3458072 & 9255748 & 2.68 \\ 
 \hline
\textbf{1995} & \textbf{559685} & \textbf{3692575} & \textbf{9897946} & \textbf{2.68} \\ 
\hline
1996 & 663110 & 4144581 & 11641286 & 2.81 \\ 
1997 & 677077 & 4340733 & 12135104 & 2.80 \\ 
1998 & 693531 & 4573584 & 12728629 & 2.78 \\ 
1999 & 709827 & 4784024 & 13280828 & 2.78 \\ 
 2000 & 721926 & 5008842 & 13810746 & 2.76 \\ 
 2001 & 727816 & 5203078 & 14261189 & 2.74 \\ 
 2002 & 747287 & 5464045 & 15001390 & 2.75 \\ 
 2003 & 786284 & 5773756 & 16024652 & 2.78 \\ 
 2004 & 826834 & 6095594 & 17167347 & 2.82 \\ 
 \hline
\textbf{2005} & \textbf{916573} & \textbf{6629595} & \textbf{19066249} & \textbf{2.88} \\ 
 \hline
\end{tabular}
\end{table}


\begin{table}[ht]
\caption{Disciplinary Datasets. PubMed and WoS were searched for articles using search terms, `immunology', `metabolism', and `applied physics'. Counts of retrieved publications are shown for each of the three years analyzed.}
\label{tab:label}
\centering
\begin{tabular}{|r r r r|}
  \hline
Year & Immunology & Metabolism & Applied Physics \\ 
  \hline
1985 & 21,606 & 78,998 & 10,298 \\ 
1995 & 29,320 & 121,247 & 21,012  \\ 
2005 & 37,296 & 200,052 & 35,600  \\ 
 \hline
\end{tabular}
\end{table}


\section{Results}
\subsection{Chacko} In our study, we also use a Monte Carlo approach to simulate under a random graph model. A  principal consideration, however, was to restrict model misspecification arising from disciplinarily irrelevant references. We addressed this consideration by restricting random substitutions to only those references in the disciplinary network being studied. We estimated model misspecification by measuring the Kullback-Leibler (K-L) Divergence~\citep{kullback_information_1951} between observed and simulated frequencies for the set of journals common to both a disciplinary network and the WoS superset (Table 3). The results indicate that simulations under our model consistently have a lower K-L divergence compared to simulations that draw from the WoS superset and its attendant substitutions that are ectopic with respect to field and discipline (Introduction).

\begin{table}[ht]
\caption{Measuring Model Misspecification. For the set of journal pairs in common between a disciplinary network and the full WoS dataset, Kullback-Leibler (K-L) divergences
between empirical and simulated journal pair frequencies were computed for the years 1985, 1995, and 2005 for the three disciplinary datasets (applied\_physics, immunology, and metabolism) using either the disciplinary network as background or the WoS superset (all\_wos) to generate the null model (Background). K-L divergence was calculated using the R seewave package with a base (logarithm) of 2. The ratio between the K-L divergence for disciplinary networks versus the full WoS ranges from 1.96 to 2.77 and is greater than 2.0 for eight out of nine cases, strongly suggesting that simulations that constrain substitutions to the given disciplinary network better model the observed data.}
\label{tab:label}
\centering
\begin{tabular}{|r lrlr r|}
  \hline
 & Disciplinary Network & Year & Background & K-L Divergence & Ratio \\ 
  \hline
1 & appl\_physics & 1985 & appl\_physics & 1.21 &  \\ 
  2 &  & 1985 & all\_wos & 2.37 & 1.96 \\ 
  3 &  & 1995 & appl\_physics & 0.86 &  \\ 
  4 &  & 1995 & all\_wos & 2.37 & 2.77 \\ 
  5 &  & 2005 & appl\_physics & 0.95 &  \\ 
  6 &  & 2005 & all\_wos & 2.35 & 2.47 \\ 
    \hline
  7 & immunology & 1985 & immunology & 0.75 &  \\ 
  8 &  & 1985 & all\_wos & 1.68 & 2.24 \\ 
  9 &  & 1995 & immunology & 0.78 &  \\ 
  10 &  & 1995 & all\_wos & 1.70 & 2.19 \\ 
  11 &  & 2005 & immunology & 0.73 &  \\ 
  12 &  & 2005 & all\_wos & 1.92 & 2.63 \\ 
    \hline
  13 & metabolism & 1985 & metabolism & 1.11 &  \\ 
  14 &  & 1985 & all\_wos & 2.24 & 2.02 \\ 
  15 &  & 1995 & metabolism & 1.07 &  \\ 
  16 &  & 1995 & all\_wos & 2.33 & 2.17 \\ 
  17 &  & 2005 & metabolism & 1.19 &  \\ 
  18 &  & 2005 & all\_wos & 2.60 & 2.18 \\ 
   \hline
\end{tabular}
\end{table}


\begin{figure}
\includegraphics[width=\hsize]{Fig1}
\caption{Fraction of publications with high conventionality (HC) and high novelty (HN) signatures relative to citation count.}
\end{figure}


\section{Discussion}


\acknowledgments
We are grateful to Kevin Boyack and Dick Klavans for constructively critical discussions. We thank the authors of Uzzi et al. (2013) for sharing their Python simulation code. Research and development reported in this publication was partially supported by Federal funds from the National Institute on Drug Abuse, National Institutes of Health, US Department of Health and Human Services, under Contract Nos. HHSN271201700053C (N43DA-17-1216) and HHSN271201800040C (N44DA-18-1216). The content of this publication is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health. TW receives funding from the Grainger Foundation. All the code used in this study is freely available from a Github site. Access to the bibliographic data analyzed in this study requires a license from Clarivate Analytics, which had no role in funding, experimental design, review of results, and conclusions presented. 

\authorcontributions 
This study was designed by GC, JB, SD, and TW. Simulations and analysis were performed by AD, GC, JB, and SD. Infrastructure and workflows used to generate data used in this study were developed by AD, DK, SL, SD, and GC.  All authors reviewed and commented on the manuscript, which was written by GC, JB, and TW.

\newpage
%%%%%%%%%%%%%%%%%%%%%%%
%% The bibliography

\bibliography{cocit_r}

%% No appendices allowed in Network Neuroscience style
%\appendix

\end{document}

\subsection{Sample Subsection}
Text here. Text here. Text here. Text here.
Text here. Text here. Text here. Text here.
Text here. Text here. Text here. Text here.
Text here. Text here. Text here. Text here.

\subsubsection{Sample Subsubsection}
Text here. Text here. Text here. Text here.
Text here. Text here. Text here. Text here.
Text here. Text here. Text here. Text here.
Text here. Text here. Text here. Text here.


\section{Sample equations}
\begin{equation}
\label{eq:rhoCHT}
\rho^{\pi}= \frac{RI + \mathbb{E}_{\pi([L,\tau_L]|\textrm{post})}
\left[C_L(\taupav+\tau_L) \right]   +
\displaystyle{\int_{0}^{P}}{dw~ \mathbb{E}_{\pi_{w_L}}}
\Biggl[\/\sum_{n_{L|[\textrm{pre},w]}}C_L(\tau_L)
\Biggr]            }      {P +
\mathbb{E}_{\pi([L,\tau_L] |\textrm{post})}[\tau_{L}] +\taupav +
\displaystyle{ \int_{0}^{P}}{dw~ \mathbb{E}_{\pi_{w_L}}}   
\Biggl[\sum_{n_{L|[\textrm{pre},w]}}\tau_L\Biggr]  
}
\end{equation}
As long as
$RI - K_LP > 
\frac{1}{\beta}$
\begin{equation}
%\def\theequation{5.1}
\left.\begin{array}{lrcl}
&\rho^{\pi} &=&  \displaystyle\frac{\beta ( RI + K_L \taupav )-1} {\beta
(P+\taupav )}    \\[12pt]
\hbox{and}\hbox to .25in{\hfill}&\mathbb{E}[\tau_L | \text{post}] &=&\displaystyle \frac{P+\taupav}{\beta ( RI -
K_LP)-1}  
\label{eq:analytical_linear}
\end{array}\right\}\hbox to 1.25in{\hfill}
\end{equation} 
Text finishing first page.
Text finishing first page.
Text finishing first page.
Text finishing first page.
Text finishing first page.
Text finishing first page.
Text finishing first page.


\begin{boxedtext}{Comparative Analysis of Different Classes of Networks} 
Going beyond the examination of shared topological features across
nervous systems, the generalized mathematical language of graph theory
also offers tools for the comparison of the organization of brain
networks to other classes of network studied
by different scientific
disciplines. 

Many real-world systems operate as some sort of
interaction or communication network, including, for example, social
networks, gene regulatory networks, computer networks, and
transportation networks. Similar to brain networks, many of these
real-world networks display an efficient small-world organization, a
pronounced community structure with densely connected modules, as well
as the formation of hubs and rich clubs. Going beyond the
comparison of networks within the class of nervous systems, the field
of `comparative network analysis' examines commonalities and
differences across a range of network classes.

\begin{figure}
\includegraphics[width=\hsize]{Fig1}
\caption{Here is the caption.}
\end{figure}
\end{boxedtext}

\newpage
\begin{boxedtext}{Comparative Analysis of Different Classes of Networks} 
Going beyond the examination of shared topological features across
nervous systems, the generalized mathematical language of graph theory
also offers tools for the comparison of the organization of brain
networks to other classes of network studied by different scientific
disciplines. Many real-world systems operate as some sort of
interaction or communication network, including, for example, social
networks, gene regulatory networks, computer networks, and
transportation networks. Similar to brain networks, many of these
real-world networks display an efficient small-world organization, a
pronounced community structure with densely connected modules, as well
as the formation of hubs and rich clubs. Going beyond the
comparison of networks within the class of nervous systems, the field
of `comparative network analysis' examines commonalities and
differences across a range of network classes.

\begin{table}[ht]
\caption{Here is the caption.}

\centerline{\begin{tabular}{|c|c|c|}
\hline
one&two&three\\
\hline
four&five&six\\
\hline
\end{tabular}}
\end{table}
\end{boxedtext}

\subsection{Jargon Samples in margin}
One common decision is between working (performing an employer-defined
task) and engaging in leisure (activities pursued for oneself). Working
leads to external rewards such as food and money; whereas leisure is
supposed to be intrinsically beneficial \jargon{Intrinsically beneficial}{The characteristic of
leisure that we enjoy most.} (otherwise one would not want to
engage in it).
%% \jargon has optional argument in square brackets where you can specify
%% the amount of extra space below where it would normally appear when 
%% two \jargon entries are in the same paragraph:
$\beta \in [0,\infty)$\jargon[24pt]{$\beta \in [0,\infty)$}{inverse temperature or degree of
stochasticity-determinism parameter.} is often used to indicate an
important parameter, the stochasticity-determinism parameter.

\subsection{Simple code sample}

\begin{code}
\begin{verbatim}
procedure bubbleSort( A : list of sortable items )
    n = length(A)
    repeat
       newn = 0
       for i = 1 to n-1 inclusive do
          if A[i-1] > A[i] then
             swap(A[i-1], A[i])
             newn = i
          end if
       end for
       n = newn
    until n = 0
end procedure
\end{verbatim}
\end{code}


\subsection{Algorithm environment}
%% \begin{algorithm} takes option [p][b][t][h],  or some combination, like \begin{figure}
%% See documentation for algorithmic.sty for more information on formatting algorithms.

\begin{algorithm}[h]
\caption{A sample in an algorithm environment.}
\begin{algorithmic}
\If {$i\geq maxval$}
    \State $i\gets 0$
\Else
    \If {$i+k\leq maxval$}
        \State $i\gets i+k$
    \EndIf
\EndIf
\end{algorithmic}
\end{algorithm}


\section{Itemized Lists}

\subsection{Roman list:}

\begin{enumerate}
\item[(i)] at high 
payoffs, subjects work almost continuously.
\item[(ii)] at low payoffs, they 
engage in leisure all at once, in long bouts after working.
\item[(iii)] subjects work continuously for the entire price duration, as long as
the price is not very long;
\item[(iv)] the duration of leisure bouts is variable.
\end{enumerate}


\subsection{Numbered list:}

\begin{enumerate}
\item at high 
payoffs, subjects work almost continuously, engaging in little leisure
inbetween work bouts; 
\item at low payoffs, they 
engage in leisure all at once, in long bouts after working, rather
than distributing the same amount of leisure time into multiple short
leisure bouts; 
\item subjects work continuously for the entire price duration, as long as
the price is not very long (as shown by an analysis conducted by
Y-AB, to be published separately);  
\item the duration of leisure bouts is variable.
\end{enumerate}


\subsection{Bulleted list:}

\begin{itemize}
\item at high 
payoffs, subjects work almost continuously, engaging in little leisure
inbetween work bouts; 
\item at low payoffs, they 
engage in leisure all at once, in long bouts after working, rather
than distributing the same amount of leisure time into multiple short
leisure bouts; 
\item subjects work continuously for the entire price duration, as long as
the price is not very long (as shown by an analysis conducted by
Y-AB, to be published separately);  
\item the duration of leisure bouts is variable.
\end{itemize}

\subsection{Description list:}
\begin{description}
\item[High payoffs:] at high 
payoffs, subjects work almost continuously, engaging in little leisure
inbetween work bouts; 
\item[Low payoffs:] at low payoffs, they 
engage in leisure all at once, in long bouts after working, rather
than distributing the same amount of leisure time into multiple short
leisure bouts; 
\item[Continuous work:] subjects work continuously for the entire price duration, as long as
the price is not very long (as shown by an analysis conducted by Y-AB, to be published separately); 
\item[Duration:] the duration of leisure bouts is variable.
\end{description}


\section{Sample figures}

\begin{figure}[h] 
\centerline{\includegraphics[width=\textwidth]{Fig1.pdf}}
\caption{(Colour online) \textbf{Task and key features of the
 data.} \\
 A) Cumulative handling time (CHT) task. Grey bars denote work
(depressing a lever), white gaps show leisure. The subject must
accumulate work up to a total period of time called the
\emph{price} ($P$) in order to obtain a single reward (black dot) of subjective reward
intensity $RI$. The trial duration is $25\times \mathrm{price}$ (plus
$2$s each time the price is attained, during which the lever is retracted so it cannot
work; not shown).}
\label{fig:task_data}
\end{figure}
%% this command ends a page but does not fill the bottom with white space:
\eject

\begin{figure}[ht] 
\widefigure{\fullpagewidth}{Fig1.pdf}
\caption{(Colour online) \textbf{Task and key features of the
 data.} \\
 A) Cumulative handling time (CHT) task. Grey bars denote work
(depressing a lever), white gaps show leisure. The subject must
accumulate work up to a total period of time called the
\emph{price} ($P$) in order to obtain a single reward (black dot) of subjective reward
intensity $RI$. The trial duration is $25\times \mathrm{price}$ (plus
$2$s each time the price is attained, during which the lever is retracted so it cannot
work; not shown).}
\label{fig:task_data2}
\end{figure}

\newpage
\section{Sample tables}

\begin{table}[!ht]
\caption{Time of the Transition Between Phase 1 and Phase 2$^{a}$}
\label{tab:label}
\centering
\begin{tabular}{lc}
\hline
 Run  & Time (min)  \\
\hline
  $l1$  & 260   \\
  $l2$  & 300   \\
  $l3$  & 340   \\
  $h1$  & 270   \\
  $h2$  & 250   \\
  $h3$  & 380   \\
  $r1$  & 370   \\
  $r2$  & 390   \\
\hline
\multicolumn{2}{l}{$^{a}$Table note text here.}
\end{tabular}
\end{table}

\begin{table}[ht]
\widecaption{Sample table taken from [treu03]\label{tbl-1}}
\begin{widetable}
\advance\tabcolsep-1pt
\small
\begin{tabular}{ccrrccccccccc}
\hline
\bf 
POS &\bf  chip &\multicolumn1c{\bf ID} &\multicolumn1c{\bf X}
&\multicolumn1c{\bf Y} &\bf
RA &\bf DEC &\bf IAU$\pm$ $\delta$ IAU &\bf
IAP1$\pm$ $\delta$ IAP1 &\bf IAP2 $\pm$ $\delta$
IAP2 &\bf star &\bf E &\bf Comment\\
\hline
0 & 2 & 1 & 1370.99 & 57.35\rlap{$^a$}    &   6.651120 &  17.131149 &
21.344$\pm$0.006\rlap{$^b$}  & 2 4.385$\pm$0.016 & 23.528$\pm$0.013 & 0.0 & 9 & -    \\
0 & 2 & 2 & 1476.62 & 8.03     &   6.651480 &  17.129572 & 21.641$\pm$0.005  & 2 3.141$\pm$0.007 & 22.007$\pm$0.004 & 0.0 & 9 & -    \\
0 & 2 & 3 & 1079.62 & 28.92    &   6.652430 &  17.135000 & 23.953$\pm$0.030  & 2 4.890$\pm$0.023 & 24.240$\pm$0.023 & 0.0 & - & -    \\
0 & 2 & 4 & 114.58  & 21.22    &   6.655560 &  17.148020 & 23.801$\pm$0.025  & 2 5.039$\pm$0.026 & 24.112$\pm$0.021 & 0.0 & - & -    \\
0 & 2 & 5 & 46.78   & 19.46    &   6.655800 &  17.148932 & 23.012$\pm$0.012  & 2 3.924$\pm$0.012 & 23.282$\pm$0.011 & 0.0 & - & -    \\
0 & 2 & 6 & 1441.84 & 16.16    &   6.651480 &  17.130072 & 24.393$\pm$0.045  & 2 6.099$\pm$0.062 & 25.119$\pm$0.049 & 0.0 & - & -    \\
0 & 2 & 7 & 205.43  & 3.96     &   6.655520 &  17.146742 & 24.424$\pm$0.032  & 2 5.028$\pm$0.025 & 24.597$\pm$0.027 & 0.0 & - & -    \\
0 & 2 & 8 & 1321.63 & 9.76     &   6.651950 &  17.131672 &
22.189$\pm$0.011  & 2 4.743$\pm$0.021 & 23.298$\pm$0.011 & 0.0 & 4 &
edge \\
\hline\\[-6pt]
\multicolumn{13}{l}{%
Table 2 is published in its entirety in the electronic
edition of the {\it Astrophysical Journal}.}\\[3pt]
\multicolumn{13}{l}{%
$^a$ Sample footnote for table 2.}\\[3pt]
\multicolumn{13}{l}{%
$^b$ Another sample footnote for table 2.}
\end{tabular}
\end{widetable}
\end{table}

\begin{table}[p]
\rotatebox{90}{\vbox{\hsize=\textheight
\caption{Here is a caption for a table that is found in landscape
mode.}
\begin{tabular}{ccrrccccccccc}
\hline
\bf 
POS &\bf  chip &\multicolumn1c{\bf ID} &\multicolumn1c{\bf X}
&\multicolumn1c{\bf Y} &\bf
RA &\bf DEC &\bf IAU$\pm$ $\delta$ IAU &\bf
IAP1$\pm$ $\delta$ IAP1 &\bf IAP2 $\pm$ $\delta$
IAP2 &\bf star &\bf E &\bf Comment\\
\hline
0 & 2 & 1 & 1370.99 & 57.35\rlap{$^a$}    &   6.651120 &  17.131149 &
21.344$\pm$0.006\rlap{$^b$}  & 2 4.385$\pm$0.016 & 23.528$\pm$0.013 & 0.0 & 9 & -    \\
0 & 2 & 2 & 1476.62 & 8.03     &   6.651480 &  17.129572 & 21.641$\pm$0.005  & 2 3.141$\pm$0.007 & 22.007$\pm$0.004 & 0.0 & 9 & -    \\
0 & 2 & 3 & 1079.62 & 28.92    &   6.652430 &  17.135000 & 23.953$\pm$0.030  & 2 4.890$\pm$0.023 & 24.240$\pm$0.023 & 0.0 & - & -    \\
0 & 2 & 4 & 114.58  & 21.22    &   6.655560 &  17.148020 & 23.801$\pm$0.025  & 2 5.039$\pm$0.026 & 24.112$\pm$0.021 & 0.0 & - & -    \\
0 & 2 & 5 & 46.78   & 19.46    &   6.655800 &  17.148932 & 23.012$\pm$0.012  & 2 3.924$\pm$0.012 & 23.282$\pm$0.011 & 0.0 & - & -    \\
0 & 2 & 6 & 1441.84 & 16.16    &   6.651480 &  17.130072 & 24.393$\pm$0.045  & 2 6.099$\pm$0.062 & 25.119$\pm$0.049 & 0.0 & - & -    \\
0 & 2 & 7 & 205.43  & 3.96     &   6.655520 &  17.146742 & 24.424$\pm$0.032  & 2 5.028$\pm$0.025 & 24.597$\pm$0.027 & 0.0 & - & -    \\
0 & 2 & 8 & 1321.63 & 9.76     &   6.651950 &  17.131672 &
22.189$\pm$0.011  & 2 4.743$\pm$0.021 & 23.298$\pm$0.011 & 0.0 & 4 &
edge \\
\hline\\[-6pt]
\multicolumn{13}{l}{%
Table 2 is published in its entirety in the electronic
edition of the {\it Astrophysical Journal}.}\\[3pt]
\multicolumn{13}{l}{%
$^a$ Sample footnote for table 2.}\\[3pt]
\multicolumn{13}{l}{%
$^b$ Another sample footnote for table 2.}
\end{tabular}
}}
\end{table}
\clearpage
\begin{boxedtext}{Tools for comparison of networks} 
Going beyond the examination of shared topological features across
nervous systems, the generalized mathematical language of graph theory
also offers tools for the comparison of the organization of brain
networks to other classes of network studied by different scientific
disciplines. 

From $\mathcal{W}$, we can estimate the variability in the fluctuations of the functional connection between nodes $i$ and $j$ over time as:
\begin{equation}
s_{ij}=\sqrt{\frac{1}{T-L}\sum_{t=1}^{T-L+1}(W_{ij}(t) - m_{ij})}
\end{equation}
where $m_{ij}=\frac{1}{T-L+1}\sum_{t=1}^{T-L+1}W_{ij}(t)$ is the mean
dynamic functional connectivity over time. 

Many real-world systems operate as some sort of
interaction or communication network, including, for example, social
networks, gene regulatory networks, computer networks, and
transportation networks. Similar to brain networks, many of these
real-world networks display an efficient small-world organization, a
pronounced community structure with densely connected modules, as well
as the formation of hubs and rich clubs. Going beyond the
comparison of networks within the class of nervous systems, the field
of `comparative network analysis' examines commonalities and
differences across a range of network classes.
\end{boxedtext}

Example of table continuing over pages:


\begin{center}
\begin{longtable}{ccc@{}}
\caption{ApJ costs from 1991 to 2013
\label{tab:table}} \\[2pt]
\hline
\bf Year & \bf Subscription & \bf Publication \\
 & \bf cost &\bf charges\\
 & \bf(\$) & \bf (\$/page)\\
\hline
\endfirsthead

\multicolumn3c{Table \thetable, \it continued from previous page.}\\[6pt]
\multicolumn3c{ApJ costs from 1991 to 2013}\\[2pt]
\hline
\bf Year & \bf Subscription & \bf Publication \\
 & \bf cost &\bf charges\\
 & \bf(\$) & \bf (\$/page)\\
\hline
\endhead
\\\hline
\\[-8pt]
\multicolumn{3}{r}{\it Table continued on next page}\\ 
\endfoot

\hline
\endlastfoot

1991 & 600 & 100 \\
1992 & 650 & 105 \\
1993 & 550 & 103 \\
1994 & 450 & 110 \\
1995 & 410 & 112 \\
1996 & 400 & 114 \\
1997 & 525 & 115 \\
1998 & 590 & 116 \\
1999 & 575 & 115 \\
2000 & 450 & 103 \\
2001 & 490 &  90 \\
2002 & 500 &  88 \\
2003 & 450 &  90 \\
2004 & 460 &  88 \\
2005 & 440 &  79 \\
2006 & 350 &  77 \\
2007 & 325 &  70 \\
2008 & 320 &  65 \\
2009 & 190 &  68 \\
2010 & 280 &  70 \\
2011 & 275 &  68 \\
2012 & 150 &  56 \\
2013 & 140 &  55 \\
\end{longtable}
\end{center}

\section{Supportive Information}
Here you enter further sources of information, if desired.

%% A possible entry might be:
% No supportive information is available at this time.



